name: compile & build & push llama-server image

on:
  #push:
  #  branches: main
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * 0'

jobs:
  build-and-push:
    runs-on: ubuntu-24.04
    permissions:
      contents: read
      packages: write

    strategy:
      matrix:
        march: [alderlake, skylake]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Log in to the GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/${{ github.repository_owner }}/llama-server-intel
          
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: ./build
          file: ./build/Dockerfile
          push: true
          tags: |
            ${{ steps.meta.outputs.tags }}-${{ matrix.march }}
          build-args: |
            MARCH=${{ matrix.march }}
          cache-from: type=gha
          cache-to: type=gha, mode=max
